---
title: "Bowen et al. 2017 Progress Report"
author: "Sean Lee"
date: "10/3/2020"
output:
  pdf_document: default
  html_document: default
---
##Week 1

##Data acquisition

My goal for this assignment was to create the Structural Equation Model (SEM) as shown in Bowen et al. 2017.  The first step in doing so would require me to get the raw data and code associated with creating this SEM.  Luckily for me, I found the a github link to the data and code imbedded in the methods section (https://github.com/jebyrnes/phrag_common_garden_sem).  

##Function parsing & correlation

After opening the link I found that it took me to a github page with a "data" folder and a "r" folder which held the code used.  I created a new project and created a data folder with all the github data in it so I could read it in later on.  I imported all the scripts which were seperated into 3 parts, part 1 included "function parsing" and "function correlation" scripts.  Function parse from what I can tell is cleaning up the data and seperating into new dataframes that will be used for downstream pathway analysis
```{r Function Parse, include=FALSE}
library(dplyr)
library(readxl)
library(tidyr)

#was functions for Jarrett originally, but the data was too correlated
func_data <- read_excel("./data/Final picrust.xlsx")


#split up the pathway types for future grouping
func_data <- separate(func_data, KEGG_Pathways, "; ", into=c("Pathway", "Subpathway", "Specific_Pathway"))
func_data <- func_data[,-1] #get rid of redundant column

#reshape to long format
func_data_long <- gather(func_data, "SampleID", "Abundance", -Pathway, -Subpathway, -Specific_Pathway)
func_data_long$SampleID <- as.character(func_data_long$SampleID)

#some summary data frames
pathway_data <- group_by(func_data_long, SampleID, Pathway) %>%
  dplyr::summarise(sum_abund = sum(Abundance, na.rm=T), mean_abund = mean(Abundance, na.rm=T)) 

#Make it wide again
pathway_data_sum <- dplyr::select(pathway_data, -mean_abund) %>%
  spread(Pathway, sum_abund)


pathway_data_mean <- dplyr::select(pathway_data, -sum_abund) %>%
  spread(Pathway, mean_abund)


subpathway_data <- group_by(func_data_long, SampleID, Subpathway) %>%
  dplyr::summarise(sum_abund = sum(Abundance, na.rm=T), mean_abund = mean(Abundance, na.rm=T))

subpathway_data_sum <- dplyr::select(subpathway_data, -mean_abund) %>%
  spread(Subpathway, sum_abund)
```

## Function correlation

This function correlation script is the script for creating the correlation maps of different biological processes and how they affect other biological processes.  It is unrelated to the SEM model.

```{r Function correlation}
library(ggplot2)
library(RColorBrewer)



###Correlation Data Frames
cor_pathways_sum <- data.frame(cor(pathway_data_sum[,-1])) %>%
  mutate(V2 = rownames(.)) %>%
  gather(V1, correlation, -V2)

cor_subpathways_sum <- data.frame(cor(subpathway_data_sum[,-1])) %>%
  mutate(V2 = rownames(.)) %>%
  gather(V1, correlation, -V2)


func_data_transpose <- select(func_data, -Pathway, -Subpathway) %>%
  gather(SampleID, Abundance, -Specific_Pathway) %>%
  spread(Specific_Pathway, Abundance)

cor_raw_pathways <- data.frame(cor(func_data_transpose[,-1])) %>%
  mutate(V2 = rownames(.)) %>%
  gather(V1, correlation, -V2)

###PLOTS
pairs(pathway_data_sum[,-1])

ggplot(data=cor_pathways_sum, mapping=aes(x=V1, y=V2, fill=correlation)) +
  geom_tile() +
  scale_fill_gradientn(colours=brewer.pal(11, "BrBG"), limits=c(-1,1))+ 
  theme(axis.text.x = element_text(angle=90, hjust=1, vjust=0.5))



ggplot(data=cor_subpathways_sum, mapping=aes(x=V1, y=V2, fill=correlation)) +
  geom_tile() +
  scale_fill_gradientn(colours=brewer.pal(11, "BrBG"), limits=c(-1,1))+ 
  theme(axis.text.x = element_text(angle=90, hjust=1, vjust=0.5))


ggplot(data=cor_raw_pathways, mapping=aes(x=V1, y=V2, fill=correlation)) +
  geom_tile() +
  scale_fill_gradientn(colours=brewer.pal(11, "BrBG"), limits=c(-1,1)) +
  theme(axis.text.x = element_text(angle=90, hjust=1, vjust=0.5))
```

## Data load : merge

The second script in the "r" folder is a script named data load:merge which just seems to be merging the experimental data from the common garden experiment to the pathway summary data created from the function parse script.

```{r}

exp_data <- read_excel("./data/common_garden_data.xlsx", sheet=2) %>%
  dplyr::rename(SampleID = `#SampleID`)

exp_data_func <- inner_join(exp_data, pathway_data_sum)

```

##SEM

The SEM model script will run until the sem.fit function at which time there is an error that indicates that that function doesn't exist.  I assume that it is an old function but I cannot find how to format the new function.

```{r}
###### Load Libraries for analysis
library(nlme)
library(lsmeans)
library(piecewiseSEM)
library(car)

###### Load data

exp_data_func <- as.data.frame(exp_data_func)

###some useful functions for piecewiseSEM use
resp <- function(i) Reduce(paste, deparse(formula(i)[[2]]))


sem.anova <- function(modlist){
  data.frame(purrr::map_df(modlist, ~{
    a <- as.data.frame(Anova(.))
    a$predictor <- rownames(a)
    a$response <- resp(.)
    a %>%
      select(response, predictor, Chisq, Df, `Pr(>Chisq)`) %>%
      rename(p_value = `Pr(>Chisq)`) %>%
      mutate(Chisq = round(Chisq,4), p_value = round(p_value, 4))
  }))
}

status_lsmeans <- function(x, ...){
  r <- resp(x)
  ret <- lsmeans(x, list(pairwise ~ status), ...)
  names(ret) <- r
  ret
}

######################### THIS IS WHAT I RAN FOR THE MODEL
exp_data_func$rd <- exp_data_func$`RNA/DNA`
exp_data_func$belowC <- exp_data_func$`below%C`
exp_data_func$belowN <- exp_data_func$`below%N`
gen_div_status <- lme(observed_otus~  status, 
                      random =~ 1|Genotype, data=exp_data_func, method="ML")
gen_activity_status <- lme(rd ~ status + observed_otus, 
                           random =~ 1|Genotype, data=exp_data_func, method="ML")
gen_meta_status <- lme(`Metabolism`~ status+ observed_otus, 
                       random =~ 1|Genotype, data=exp_data_func, method="ML")
phen_mod_status <- lme(belowgallic_uM ~ rd + observed_otus + Metabolism + status, 
                       random =~ 1|Genotype, data=exp_data_func, method="ML")
c_mod_status <- lme(belowC ~ rd + observed_otus + Metabolism + status + belowgallic_uM +
                      belowbiomass_g + abovebiomass_g, 
                     random =~ 1|Genotype, data=exp_data_func, method="ML")
n_mod_status <- lme(belowN ~ rd + observed_otus + Metabolism + status +
                      belowbiomass_g + abovebiomass_g, 
                     random =~ 1|Genotype, data=exp_data_func, method="ML")

biomass_mod_status <- lme(belowbiomass_g ~ rd + belowgallic_uM +  
                            observed_otus + Metabolism + status, 
                          random =~ 1|Genotype, data=exp_data_func, method="ML")
Abiomass_mod_status <- lme(abovebiomass_g ~ rd + belowgallic_uM + 
                             observed_otus + Metabolism + status, 
                           random =~ 1|Genotype, data=exp_data_func, method="ML")

sem_mod_nlme <- list(
  gen_div_status,
  gen_activity_status,
  gen_meta_status,
  phen_mod_status,
  c_mod_status,
  n_mod_status,
  biomass_mod_status,
  Abiomass_mod_status
  
)
```

## The problem!

When the script reached the "get SEM fit information"

    sem.fit(sem_mod_nlme, data=exp_data_func, 
        corr.errors=c("belowbiomass_g~~abovebiomass_g", "belowN ~~           belowC"))

I found that it gave me this error:

    Error in sem.fit(sem_mod_nlme, data = exp_data_func, corr.errors     = c("belowbiomass_g~~abovebiomass_g",  : 
    could not find function "sem.fit"
    
At this point I needed to assess what I knew and how I would go about solving this issue.

## Week 2

To this point I have downloaded all the data and scripts from
github and have ran through all of the "Function parsing and correlations" which broke down the data and created correlation maps of different biological processes and how they affect other biological processes.  These again are unrelated to the final SEM model I am interested in.

## learning more about SEMs and piecewise SEM

 I realized in trying to recreate Bowen et al. 2017 that I needed to actually understand what the code was actually doing.  As I was working through recreating Bowen et al. 2017's SEM model I was clueless on what each line of code was actually doing and how each component of the code ultimately fed into the final SEM model.
  When I was reseaching how to rewrite the code from Bowen et al. 2017 to work with the current version of piecewiseSEM I was brought to the github page created by the person who wrote The piecewiseSEM package, Jonathan S. Lefcheck.  

(http://jslefche.github.io/piecewiseSEM/articles/piecewiseSEM.html)

  I opened up the site and started reading the intro into SEM.  The basic concept was pretty simple in that it was a model used to establish relationships between multiple variables, through the creation of these casual networks one can establish strength and direction of direct and indirect effects of these variables.
  Whie delving headfirst into creating an SEM would have been fun, I thought I'd need some further background on how SEM's worked.  I found these videos on Youtube created by Dr. Erin M. Buchanan at Missouri State University.
  
Pt. 1
https://www.youtube.com/watch?v=2LzZvi43pGE&list=RDCMUCMdihazndR0f9XBoSXWqnYg&start_radio=1&t=87

Some basics that were mentioned in the lesson 
•	Can test multiple regressions at the same time, multiple x and y variables
•	Can test theorized causal relationships even if the researcher doesn’t initially measure the variables in a causal way
•	Error can be attributed to different parts of model rather than lumping error term together with multiple variables
Concept
	
Latent variables
•	Abstract phenomena you are trying to model in SEM (latent variables)
o	i.e. IQ, many things you can do to measure IQ but not tangible metric
•	this latent variable is linked to multiple measured variables i.e. test scores
•	it is represented indirectly by these collective variables
	
manifest or observed variables
•	measured variables, what you are actually measuring (i.e. test scores)
•	exogenous variables are variables that causal, or your independent variables
o	arrows will be going out of these variables
•	exogenous variables will not have error terms as change in these variables are represented by things you are not measuring in model (i.e. age, gender, etc.)
•	all endogenous variables have to have an error term because x(exogenous) causes y(endogenous)
o	x to predict y so there is some uncertainty about y since not getting 100% correct 
•	endogenous terms are dependent variables and arrows always leading into them
Measurement model
•	relationship between an exogenous latent variable and measured variables
•	have this latent variable think affects change ob these endogenous variables
•	i.e. we think IQ affects the SAT scores
•	these endogenous variables show what the latent variable is
•	modelling phenomena with the output of the endogenous variables
Full SEM
•	latent variable that explains latent variable that explains endogenous variable
•	variables can thus be endogenous and exogenous
•	In measurement model the 2nd circle is exogenous but in full SEM it is endogenous
•	nonRecursive model model variables can feedback on itself while the recursive the model flows in one way

hypothesis testing
•	theory building technique
•	building model to create working theory
 
•	you want data to match model
•	you want your model to be the null model
•	model things that exist rather than find significant differences to a null
•	models should explain phenomena regardless of what dataset used as the null is the norm in the world
•	 how well does our model explain the phenomena?
•	Model fit based on residuals, residuals being the error for latent variables
•	Y(persons score=data)=model(x variables)+error(residuals)
•	Since residuals are error estimated based on model it is latent (circle)
•	Low error implies data = model is more accurately modeling the phenomena you are trying to represent
•	  
•	Double error represents correlation as not sure which direction relationship is flowing

Path diagrams
 
•	X predicts y direct effect
•	X predicts z predicts y indirect effects
•	Usually would have to run 3 regressions but in SEM all in one model

Whole picture
•	 
•	Measurement model portion has one latent exogenous variable predicting the square endogenous variables and each endogenous variable gets own error term associated with it
•	Structural model has another latent exogenous variable predicting this measurement models exogenous variable that is now endogenous
•	In testing model you have to see adequacy o the model, does the x2 fit the indices?
•	In terms of theory testing does the model reflect what you hypothesized?

1. An Introduction to Structural Equation Modeling from Jonathan S. Lefcheck

  Equiped with some basic knowledge on how SEM's worked I began to work my way through the github page for piecewise SEM which is linked above.  In the example we are creating a very simple SEM using 4 variables variable x1 is exogenous to variable y1 and y2, y2 is also exogenous to y1 which is in turn exogenous to y3.
  Traditionally SEM is hard to use to analyze ecological data as the assumptions assume that data is independent and that errors are normally distributed is often not met.  
  Piecewise SEM was created and differs from traditional SEM in that each relationship between variables is estimated independently. Each local response is decomposed into individual linear or multiple regressions are used to  

```{r}

library(piecewiseSEM)
```
 
the tutorial uses this sample dataset to fit a model using piecewiseSEM.
```{r}
dat <- data.frame(x1 = runif(50), y1 = runif(50), y2 = runif(50), y3 = runif(50))
dat
```

Using the "psem" function which is part of piecewiseSEM we create a series of linear regressions between the different factors.

running this code however:

model <- psem(lm(y1 ~ x1, dat), lm(y1 ~ y2, dat), lm(y2 ~ x1, dat), lm(y3 ~ y1, dat))

gives the error:

Error: Duplicate responses detected in the model list. Collapse into single multiple regression!

This is to say that the code displayed above runs all the individual component regressions which lists each "path" separately.  "psem" collapses these regressions into a single multiple regression in the following format

```{r}
model <- psem(lm(y1 ~ x1 + y2, dat), lm(y2 ~ x1, dat), lm(y3 ~ y1, dat))
model
```
 to evaluate the model we call a summary of the psem object we created "model".
```{r}
summary(model, .progressBar = F)
```
# Standardization of coefficients

To compare the relative strength of the different predictors used in the model you must standardize them.  Allows for effects to be compared across multiple responses and allows for indirect and total responses to be calculated using the multiple responses.  piecewiseSEM has multiple techniques and ways to standardize coefficients and I decided the run through them all.

First the practice asked me to create another fake dataset "coefs.data"

```{r}
coefs.data <- data.frame(
  y = runif(100),
  x1 = runif(100),
  x2 = runif(100)
)

model<-lm(y~x1,coefs.data)
model
```


# No standard
 
 In some circumstances when all responses are already scaled to the same standard or in some cases you don't want your response variables to be standardized you can specify no standardization
```{r}
coefs(model, standardize = "none")

summary(model)$coefficients

## to return intercept

coefs(model, standardize = "none", intercepts = TRUE)
```
 
# standardization by standard deviation

One of the most common ways of standardization is to making the coefficients in terms of standard deviation of the mean; this is done by scaling the coefficient beta by the standard dev of x/y.

```{r}
# Obtain the raw coefficient from the coefficient table
B <- summary(model)$coefficients[2, 1]

# Compute the standard deviation of the independent variable
sd.x <- sd(coefs.data$x1)

# Compute the standard deviation of the dependent variable
sd.y <- sd(coefs.data$y)

# Scale Beta
B.sdscaled <- B * sd.x/sd.y
```

Now that we got the scaled beta by hand we can compare it to the "scale" standardization option in the "coefs" function. This "scale" option standardizes by st. dev.

```{r}
coefs(model, standardize = "scale")

B.sdscaled
```
Amazing! it's a match.

# Scaling by relevant ranges

Default scaling assumes you use the whole range of the dataset, but sometimes the best way to scale the data is to standardize across a relevant range

# range standardizatin by hand
```{r}
# Calculate range for the independent variable
range.x <- diff(range(coefs.data$x1))

# Calculate range for the independent variable
range.y <- diff(range(coefs.data$y))

# Scale Beta
B.range <- B * range.x/range.y
```

In "coefs" function the "range" option for the "standardize" argument standardizes the coefficients based on range difference between the variables.
```{r}
coefs(model, standardize = "range")
B.range
```
 They're the same! Amazing!
 
## GLM in pSEM

SEM shown in the example is one where x1 affects both y1 and y2 which both influence y3.  This SEM has two independence claims:

1.y3 | x1 (y1, y2)

2. y2 | y1 (x1)

Assuming we live in a gaussian world, the second independence claim should have significance values that are equal whether the test is conducted as y2 | y1 (x1) or y1 | y2 (x1).

If however we use GLM's with non-normally distributed data to generate either of the variables this would not be true.  By transforming the data the regression of y2 against y1 is going to be different than y1 regressed against y2.

The example data we generate is using a poisson distribution rather than normal to demonstrate the above statement.

```{r}
# Generate fake data
glmdat <- data.frame(x1 = runif(50), y1 = rpois(50, 10), y2 = rpois(50, 50), y3 = runif(50))

# Extract P-values
summary(lm(y1 ~ y2 + x1, glmdat))$coefficients[2, 4]
```

```{r}
summary(lm(y2 ~ y1 + x1, glmdat))$coefficients[2, 4]
```

If you are using normally distributed data then the y1 against y2 regression same as y2 against y1, amazing!

Let's try it using a poisson distribution.

```{r}
# Repeat but model y1 and y2 and Poisson-distributed
summary(glm(y1 ~ y2 + x1, "poisson", glmdat))$coefficients[2, 4]
```

```{r}
summary(glm(y2 ~ y1 + x1, "poisson", glmdat))$coefficients[2, 4]
```

When the variables y1 and y2 are poisson distributed the regression of y1 against y2 and y2 against y1 yield different significance values!

This can be problematic when performing d-seperation tests which test independence of variables not connected by an arrow while controlling variables on which these paths are conditional.  If the p-values are biased on one path vs. another then this can hinder the d-seperation test and also the goodness of fit test which can be over or underestimated based on this bias.

pSEM can solve this issue by:

1. prescribing the directionality of the tests, so you can specify y2 against y1 rather than y1 against y2

2.  One can remove one of the paths and designate it as a correlated error by using %~~%

3.  One can conduct both tests and choose the most conservative which is the one with the lowest P-value.

Let's make some fake data to demonstrate this...

```{r}
# Generate fake data
glmdat <- data.frame(x1 = runif(50), y1 = rpois(50, 10), y2 = rpois(50, 50), y3 = runif(50))

# Construct SEM
glmsem <- psem(
  glm(y1 ~ x1, "poisson", glmdat),
  glm(y2 ~ x1, "poisson", glmdat),
  lm(y3 ~ y1 + y2, glmdat)
)

#summary(glmsem)

#Error: Non-linearities detected in the basis set where P-values are not symmetrical. This can bias the outcome of the tests of directed separation. Offending independence claims: y2 <- y1 *OR* y2 -> y1 
#Option 1: Specify directionality using argument 'direction = c()' in 'summary'. 

#Option 2: Remove path from the basis set by specifying as a correlated error using '%~~%' in 'psem'. 

#Option 3 (recommended): Use argument 'conserve = TRUE' in 'summary' to compute both tests, and return the most conservative P-value.
```

#Option 1: Specify directionality using argument 'direction = c()' in 'summary'. 

In option 1 they ask to specify the directionality of the argument using the direction = c() function in the summary function

```{r}
summary(glmsem, direction = c("y1 <- y2"), .progressBar = F)$dTable

```
#Option 2: Remove path from the basis set by specifying as a correlated error using '%~~%' in 'psem'. 

In option 2 we can remove one of the paths altogether, I guess just another way of specifying the path.

```{r}
summary(update(glmsem, y1 %~~% y2), .progressBar = F)
```
Note that the claim no longer appears in the section for the tests of directed separation.

#Option 3 (recommended): Use argument 'conserve = TRUE' in 'summary' to compute both tests, and return the most conservative P-value.

we use the conserve = TRUE argument to pick the path that is most conservative "lowest p-value"

```{r}
summary(glmsem, conserve = T, .progressBar = F)$dTable
```
this seems to be y2~y1 so it chose it!

## Correlated error

correlated error is when there is no unidirectional relationship between two variables and the can affect one another bidirectionally.

the model they describe in the practice is a lot like the one above, x1 affects both y1 and y2 unidirectinally and those two variables affect y3.  But, in this example y1 and y2 are correlated bidirectionally.

in pSEM we use the %~~% argument to indicate correlated error between two different variables

```{r}
cordat <- data.frame(x1 = runif(50), y1 = runif(50), y2 = runif(50), y3 = runif(50))

corsem <- psem(
  lm(y1 ~ x1, cordat),
  lm(y2 ~ x1, cordat),
  y1 %~~% y2, 
  lm(y3 ~ y1 + y2, cordat)
)

summary(corsem, .progressBar = F)
```
In the correlated error shown above y1 and y2 are both exogenous variables and this error is calculated by performing a correlation test (cor.test) after removing the influence of the endogenous variable x1.

```{r}
cor(resid(lm(y1 ~ x1, cordat)), resid(lm(y2 ~ x1, cordat)))
```
```{r}
cerror(y1 %~~% y2, corsem)
```

## Nested models and AIC

piecewise SEM can fascilitate model comparison using comparison of model AIC scores

consider two models you are trying to compare:

SEM1 where x1 is exogenous to y1 and y2, y1 which is exogenous to y2 and y2 which is exogenous to y3

SEM2 is the same as SEM1 barring the fact that it has no y3 variable

you'd think to compare them you just use the AIC function but...

```{r}
AICdat <- data.frame(x1 = runif(50), y1 = runif(50), y2 = runif(50), y3 = runif(50))

sem1 <- psem(
  lm(y1 ~ x1, AICdat),
  lm(y2 ~ y1, AICdat),
  lm(y3 ~ y2, AICdat)
)

sem2 <- psem(
  lm(y1 ~ x1, AICdat),
  lm(y2 ~ y1, AICdat)
)

AIC(sem1, sem2)
```
The issue with this is that the 2nd sem does not account for the missing y3 varialble which is apparently important in calculating fischers C

```{r}
sem2new <- update(sem2, y3 ~ 1)

AIC(sem1, sem2new)
```


## Moving into "Comparing package versions"

   The next section of the manual talks about reconciling different versions of the piecewisSEM package.  This is the section that should be able to solve initial issue with running Bowen et al. 2017 SEM.

## The problem

The main problem I had when trying to run the SEM model was that all the previous scripts leading up the the SEM model were running perfectly, but when it came to the SEM model there was an error that popped up.  The error read: 

Error in sem.fit(sem_mod_nlme, data = exp_data_func, corr.errors = c("belowbiomass_g~~abovebiomass_g",  : 
  could not find function "sem.fit"
  
It seems as though the sem.fit function has since been replaced by a new function or somehow the syntax of the new version may be different.  Looking back to when the author originally used the "piecewiseSEM" package they were likely using version 1.x, and the current package my system has loaded in verion 2.1.0. 

To find how the "piecewiseSEM" package has changed from verion 1.x to 2.1.0 I looked up "piecewiseSEM" on google to find a page from "The Comprehensize R Archive Network" (https://cran.r-project.org/web/packages/piecewiseSEM/vignettes/piecewiseSEM.html) which describes how to use the "piecewiseSEM" package.

In section 3.2 "Comparing versions in evaluating the Shipley’s SEM" the author describes that the old version of the package the model was run off of a constructed "list" of linear models.  For example from bowen et al. 2017:
```{r}
gen_div_status <- lme(observed_otus~  status, 
                      random =~ 1|Genotype, data=exp_data_func, method="ML")
  gen_activity_status <- lme(rd ~ status + observed_otus, 
                           random =~ 1|Genotype, data=exp_data_func, method="ML")
  gen_meta_status <- lme(`Metabolism`~ status+ observed_otus, 
                       random =~ 1|Genotype, data=exp_data_func, method="ML")
  phen_mod_status <- lme(belowgallic_uM ~ rd + observed_otus + Metabolism + status, 
                       random =~ 1|Genotype, data=exp_data_func, method="ML")
  c_mod_status <- lme(belowC ~ rd + observed_otus + Metabolism + status + belowgallic_uM     +
                      belowbiomass_g + abovebiomass_g, 
                    random =~ 1|Genotype, data=exp_data_func, method="ML")
  n_mod_status <- lme(belowN ~ rd + observed_otus + Metabolism + status +
                      belowbiomass_g + abovebiomass_g, 
                    random =~ 1|Genotype, data=exp_data_func, method="ML")

  biomass_mod_status <- lme(belowbiomass_g ~ rd + belowgallic_uM +  
                            observed_otus + Metabolism + status, 
                          random =~ 1|Genotype, data=exp_data_func, method="ML")
  Abiomass_mod_status <- lme(abovebiomass_g ~ rd + belowgallic_uM + 
                             observed_otus + Metabolism + status, 
                           random =~ 1|Genotype, data=exp_data_func, method="ML")

  sem_mod_nlme <- list(
    gen_div_status,
    gen_activity_status,
    gen_meta_status,
    phen_mod_status,
    c_mod_status,
    n_mod_status,
    biomass_mod_status,
    Abiomass_mod_status
  
    )
```

    
This created a list of all the linear models fed into the SEM model called "sem_mod_nmle". 

## Solving the problem 

The new version of the the package omits the list and uses the "psem" function which converts the list into this "psem" object.  So I edited the chunk of code seed above to this new one:
```{r}
bowen.psem<-psem(lme(observed_otus~  status, 
                                       random =~ 1|Genotype, data=exp_data_func, method="ML"),
                 lme(rd ~ status + observed_otus, 
                                            random =~ 1|Genotype, data=exp_data_func, method="ML"),
                 lme(`Metabolism`~ status+ observed_otus, 
                                        random =~ 1|Genotype, data=exp_data_func, method="ML"),
                 lme(belowgallic_uM ~ rd + observed_otus + Metabolism + status, 
                                        random =~ 1|Genotype, data=exp_data_func, method="ML"),
                 lme(belowC ~ rd + observed_otus + Metabolism + status + belowgallic_uM +
                                       belowbiomass_g + abovebiomass_g, 
                                     random =~ 1|Genotype, data=exp_data_func, method="ML"),
                 lme(belowN ~ rd + observed_otus + Metabolism + status +
                                       belowbiomass_g + abovebiomass_g, 
                                     random =~ 1|Genotype, data=exp_data_func, method="ML"),
                 lme(belowbiomass_g ~ rd + belowgallic_uM +  
                                             observed_otus + Metabolism + status, 
                                           random =~ 1|Genotype, data=exp_data_func, method="ML"),
                 lme(abovebiomass_g ~ rd + belowgallic_uM + 
                                              observed_otus + Metabolism + status, 
                                            random =~ 1|Genotype, data=exp_data_func, method="ML"))

  (sem_mod_nlme <- summary(bowen.psem, .progressBar = F))
  
# This summary gave me the SEM fit information


```

 
##Getting the coefficients from the fit model

The "sem.coefs" function used by Bowen et al. 2017 was also out of date so I checked the CRAN page to see what the new procedure was.  The new function is simply "coefs" and you plug your "psem" object right into it.  So I ran coefs(bowen.psem) and got:

```{r}
coefs(bowen.psem,intercepts = TRUE)
```

## Evaluate Chi Square tests of parameter significance

```{r}
sem.anova(sem_mod_nlme)

## creates CSV of chi square tests for parameter significance
write.csv(sem.anova(sem_mod_nlme), "./sem_chisq.csv", row.names=FALSE)

##

ph_tests <- lapply(sem_mod_nlme, status_lsmeans, adjust="none")
ph_comp <- lapply(ph_tests, function(x) x[[2]])
names(ph_comp) <- sapply(ph_tests, function(x) names(x)[1])
ph_comp_tab <- do.call(rbind, lapply(ph_comp, function(x) as.data.frame(print(x))))
write.csv(ph_comp_tab, "./post_hocs.csv", row.names=TRUE)
```

## Actually making a figure depicting the SEM coefficients
   
   The figure depicting the SEM is kind of what I was trying to make the whole time.  These SEM figures, if you are not familiar,show these exogenous and endogenous variables that are connected by arrows which depicts the direction of influence. The strength of these interactions is sometimes depicted through the width of arrows and/or coefficients displayed near the arrows.  
   Looking at the provided scripts from the Bowen et al. 2017 Github repository I found no code describing how the figure in the paper was made.  Looking online at resources that would help me construct this path diagram yielded nothing when it comes to creating these in R. There seems to be a way to create path diagrams using SEMs constructed in the package "lavaan" but nothing of the sort in "piecewiseSEM".  I have concluded that Bowen et al. 2017 simply took the coefficients outputted by the SEM and created the path diagram in some 3rd party software.  
   At this point I don't think investing time into making a path diagram would be within the scope of this class.
   
## Conclusions

  This exercise in reproducibility within academic papers has shown me that even if the author provides have all the scripts and the data upon publishing the paper there could still be pitfalls with reproducibility.  Mainly, that the packages the author uses to perform certain analyses or construct certain figures are tied to the developer of that package.  If the developer decides to update the package at any given point the syntax, functions, and arguments could completely change.  Given that the paper I chose was only 3 years old and some of the code was already out of date this demonstrates that these packages are constantly being changed making the nature of reproducibility increasingly complicated as you would have to understand how to edit the old code to run with the updated package.
  Overall I think that Bowen et al. 2017 did a better than average job when it comes to overall reproducibility, it was just the nature of R packages that ultimately gave me some problems

```
   

